Namespace(adam_epsilon=1e-08, batch_size_per_gpu=1, cache_path='/data/mathieu/hf_models/t5-v1-base/', concat_mode='right_concat', counterfactual_removal=False, cuda='2', data_dir='/data/mathieu/DATASETS/PromptSumm/', dataset='cnndm', dataset_cache_dir='../../hf_datasets/', dataset_name='ccdv/cnn_dailymail', dataset_version='3.0.0', eval_step=100000, few_shot=10, gradient_accumulation_steps=8, guidance_mode='normal', guidance_type='ents', highlights=True, ifckpt_onlymodel=1, length_penalty=1.0, lm_adapted_path='/data/mathieu/lm_adapted_t5model/torch_ckpt/base/pytorch_model.bin', local_rank=0, log_step=1, lr=0.5, max_epoch=30, max_grad_norm=1.0, max_guidance_length=100, max_length=512, max_summary_length=128, model='T5MixPrompt', model_name='google/t5-v1_1-base', num_beams=4, num_seeds=3, num_workers=0, prompt_number=300, repetition_penalty=2.5, save_model=False, save_model_path='', save_step=100000, seed=42, separator=',', stemmer=True, summary_key='highlights', test_key='test', test_size_per_gpu=8, text_key='article', train_sample=True, use_bert_tagger=False, use_lm_adapted=1, valid_size_per_gpu=8, validation_key='validation', warmup_steps=0.01, weight_decay=1e-05)

Mix prompt tuning
use lm adapted model!

Entity-level eval, mean precision: 32.5000, recall: 10.8929, F-1: 15.4394

Entity-level eval, mean precision: 29.0476, recall: 16.3095, F-1: 18.7837

Entity-level eval, mean precision: 49.5556, recall: 18.3929, F-1: 23.6153

Entity-level eval, mean precision: 21.6667, recall: 12.6786, F-1: 13.7319

Entity-level eval, mean precision: 5.8333, recall: 8.0357, F-1: 6.7500

Entity-level eval, mean precision: 20.4182, recall: 15.7143, F-1: 16.6676

Entity-level eval, mean precision: 21.8889, recall: 14.6429, F-1: 15.6863

Entity-level eval, mean precision: 28.3571, recall: 26.0595, F-1: 23.9649

Entity-level eval, mean precision: 17.2381, recall: 16.1310, F-1: 15.4225

Entity-level eval, mean precision: 23.6970, recall: 23.7381, F-1: 21.3156

Entity-level eval, mean precision: 26.6722, recall: 17.3214, F-1: 20.0350

Entity-level eval, mean precision: 35.2657, recall: 31.1786, F-1: 29.5545

Entity-level eval, mean precision: 34.6538, recall: 41.9881, F-1: 35.6581

Entity-level eval, mean precision: 33.3926, recall: 38.7381, F-1: 33.7753

Entity-level eval, mean precision: 37.9402, recall: 50.1667, F-1: 42.1047

Entity-level eval, mean precision: 39.1245, recall: 48.0833, F-1: 42.2475

Entity-level eval, mean precision: 35.8626, recall: 38.9881, F-1: 36.4072
