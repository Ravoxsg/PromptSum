Namespace(adam_epsilon=1e-08, batch_size_per_gpu=1, cache_path='/data/mathieu/hf_models/t5-v1-base/', concat_mode='right_concat', counterfactual_removal=False, cuda='2', data_dir='/data/mathieu/DATASETS/PromptSumm/', dataset='cnndm', dataset_cache_dir='../../hf_datasets/', dataset_name='ccdv/cnn_dailymail', dataset_version='3.0.0', eval_step=100000, few_shot=10, gradient_accumulation_steps=8, guidance_mode='normal', guidance_type='ents', highlights=True, ifckpt_onlymodel=1, length_penalty=1.0, lm_adapted_path='/data/mathieu/lm_adapted_t5model/torch_ckpt/base/pytorch_model.bin', local_rank=0, log_step=1, lr=0.5, max_epoch=30, max_grad_norm=1.0, max_guidance_length=50, max_length=512, max_summary_length=128, model='T5MixPromptDID', model_name='google/t5-v1_1-base', num_beams=4, num_seeds=3, num_workers=0, prompt_number=300, repetition_penalty=2.5, save_model=False, save_model_path='', save_step=100000, seed=42, separator=',', stemmer=True, summary_key='highlights', test_key='test', test_size_per_gpu=8, text_key='article', train_sample=True, use_bert_tagger=False, use_lm_adapted=1, valid_size_per_gpu=8, validation_key='validation', warmup_steps=0.01, weight_decay=1e-05)

Mix prompt tuning with discrete prompt in decoder
use lm adapted model!

Entity-level eval, mean precision: 10.0000, recall: 1.4286, F-1: 2.5000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 10.0000, recall: 1.4286, F-1: 2.5000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 10.0000, recall: 1.4286, F-1: 2.5000

Entity-level eval, mean precision: 10.0000, recall: 1.4286, F-1: 2.5000

Entity-level eval, mean precision: 10.0000, recall: 1.4286, F-1: 2.5000

Entity-level eval, mean precision: 10.0000, recall: 1.4286, F-1: 2.5000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 10.0000, recall: 1.4286, F-1: 2.5000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 5.0000, recall: 2.5000, F-1: 3.3333

Entity-level eval, mean precision: 5.0000, recall: 2.5000, F-1: 3.3333

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 3.3333, recall: 2.5000, F-1: 2.8571

Entity-level eval, mean precision: 5.0000, recall: 2.5000, F-1: 3.3333

Entity-level eval, mean precision: 5.0000, recall: 2.5000, F-1: 3.3333

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 5.0000, recall: 2.5000, F-1: 3.3333

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 3.3333, recall: 2.5000, F-1: 2.8571

Mix prompt tuning with discrete prompt in decoder
use lm adapted model!

Entity-level eval, mean precision: 10.0000, recall: 2.5000, F-1: 4.0000

Entity-level eval, mean precision: 10.0000, recall: 2.5000, F-1: 4.0000

Entity-level eval, mean precision: 10.0000, recall: 2.5000, F-1: 4.0000

Entity-level eval, mean precision: 5.0000, recall: 2.5000, F-1: 3.3333

Entity-level eval, mean precision: 10.0000, recall: 2.5000, F-1: 4.0000

Entity-level eval, mean precision: 10.0000, recall: 2.5000, F-1: 4.0000

Entity-level eval, mean precision: 3.3333, recall: 2.5000, F-1: 2.8571

Entity-level eval, mean precision: 3.3333, recall: 2.5000, F-1: 2.8571

Entity-level eval, mean precision: 2.5000, recall: 2.5000, F-1: 2.5000

Entity-level eval, mean precision: 10.0000, recall: 2.5000, F-1: 4.0000

Entity-level eval, mean precision: 5.0000, recall: 2.5000, F-1: 3.3333

Entity-level eval, mean precision: 2.5000, recall: 2.5000, F-1: 2.5000

Entity-level eval, mean precision: 2.5000, recall: 2.5000, F-1: 2.5000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 5.0000, recall: 2.5000, F-1: 3.3333

Entity-level eval, mean precision: 6.6667, recall: 5.0000, F-1: 5.7143

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 6.6667, recall: 5.0000, F-1: 5.7143

Entity-level eval, mean precision: 5.0000, recall: 5.0000, F-1: 5.0000

Entity-level eval, mean precision: 5.0000, recall: 2.5000, F-1: 3.3333

Entity-level eval, mean precision: 6.0000, recall: 5.0000, F-1: 5.4545

Entity-level eval, mean precision: 5.0000, recall: 5.0000, F-1: 5.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Mix prompt tuning with discrete prompt in decoder
use lm adapted model!

Entity-level eval, mean precision: 5.0000, recall: 1.4286, F-1: 2.2222

Entity-level eval, mean precision: 5.0000, recall: 1.4286, F-1: 2.2222

Entity-level eval, mean precision: 5.0000, recall: 1.4286, F-1: 2.2222

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 5.0000, recall: 1.4286, F-1: 2.2222

Entity-level eval, mean precision: 5.0000, recall: 1.4286, F-1: 2.2222

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 5.0000, recall: 1.4286, F-1: 2.2222

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 3.3333, recall: 4.4444, F-1: 3.8095

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 1.6667, recall: 2.2222, F-1: 1.9048

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 1.6667, recall: 2.2222, F-1: 1.9048

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000

Entity-level eval, mean precision: 0.0000, recall: 0.0000, F-1: 0.0000
final results:
best_val_mean_rouge: 3.7733447618192435
val_rouge1: 4.568333292024396
val_rouge2: 2.3102315782728153
val_rougeL: 4.441469415160518
precision: 4.444444444444445
recall: 3.9814814814814814
f1: 4.047619047619048
